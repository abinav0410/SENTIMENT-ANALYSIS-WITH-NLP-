!pip install -q scikit-learn pandas joblib matplotlib nltk


import pandas as pd
import numpy as np
import re, string, joblib
import matplotlib.pyplot as plt
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from google.colab import files

RANDOM_STATE = 42


print("ðŸ‘‰ Upload your dataset (CSV with 'text' and 'label' columns)")
uploaded = files.upload()

for file_name in uploaded.keys():
    df = pd.read_csv(file_name)
    print(f"\nLoaded '{file_name}' with shape:", df.shape)
    display(df.head())


"""
pos = ["I love this product, it works great and I'm very happy!",
       "Excellent service and quality. Highly recommend."] * 120
neg = ["Terrible experience. The item broke after one day.",
       "Very disappointed. Not as described and poor support."] * 120
texts = pos + neg
labels = [1]*len(pos) + [0]*len(neg)
df = pd.DataFrame({'text': texts, 'label': labels})
"""



def preprocess_text(s):
    s = str(s).lower()
    s = re.sub(r"http\\S+|www\\S+|\\S+@\\S+", " ", s)
    s = s.translate(str.maketrans('', '', string.punctuation))
    s = re.sub(r"\\s+", " ", s).strip()
    return s

df['text_clean'] = df['text'].apply(preprocess_text)
print("\n Text cleaning done!")
display(df.head())


tfidf = TfidfVectorizer(max_features=5000, ngram_range=(1,2), min_df=2)
X = tfidf.fit_transform(df['text_clean'])
y = df['label']
print("TF-IDF matrix shape:", X.shape)


X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y
)
print("Training size:", X_train.shape[0], " | Test size:", X_test.shape[0])


param_grid = {'C': [0.01, 0.1, 1, 5, 10]}
lr = LogisticRegression(solver='liblinear', random_state=RANDOM_STATE, max_iter=1000)
gs = GridSearchCV(lr, param_grid, cv=2, scoring='f1', n_jobs=-1, verbose=1) # Reduced cv to 2
gs.fit(X_train, y_train)

print("\nBest parameters:", gs.best_params_)
print("Best CV score:", gs.best_score_)


best_model = gs.best_estimator_
y_pred = best_model.predict(X_test)

print("\n Evaluation Results:")
print("Accuracy:", accuracy_score(y_test, y_pred))
print("\nClassification Report:\n", classification_report(y_test, y_pred))

cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(5,4))
plt.imshow(cm, interpolation='nearest')
plt.title("Confusion Matrix")
plt.colorbar()
plt.ylabel("True label")
plt.xlabel("Predicted label")

for i in range(cm.shape[0]):
    for j in range(cm.shape[1]):
        plt.text(j, i, cm[i, j], ha='center', va='center', color='red', fontsize=12)
plt.show()


joblib.dump(tfidf, 'tfidf_vectorizer.joblib')
joblib.dump(best_model, 'logistic_model.joblib')
print("\n Model and vectorizer saved!")


def predict_sentiment(texts):
    texts_clean = [preprocess_text(t) for t in texts]
    X_new = tfidf.transform(texts_clean)
    preds = best_model.predict(X_new)
    probs = best_model.predict_proba(X_new)[:,1]
    return list(zip(texts, preds, probs))

examples = [
    "I absolutely love this product, will buy again!",
    "This is terrible. Waste of money.",
]
results = predict_sentiment(examples)
print("\n Sample Predictions:")
for t, p, prob in results:
    print(f"{t}\n  â†’ Sentiment: {'Positive' if p==1 else 'Negative'} (prob={prob:.3f})\n")

print("\n Sentiment analysis pipeline completed successfully!")